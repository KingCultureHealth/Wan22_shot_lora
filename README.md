# Wan22_shot_lora ğŸ¬

![Model Status](https://img.shields.io/badge/Status-Active-success) ![Task](https://img.shields.io/badge/Task-Text2Video%20%7C%20Image2Video-blue)

**Wan22_shot_lora** is a specialized Low-Rank Adaptation (LoRA) model designed for the Wan2.2 video generation architecture. 

Its primary goal is to **break the continuity** typically found in AI videos and introduce **dynamic shot changes, scene cuts, and transitions**. It works effectively for both Text-to-Video (T2V) and Image-to-Video (I2V) workflows.

## âœ¨ Key Features

*   **Cinematic Cuts:** Enables the model to generate videos that switch between different angles (e.g., Close-up â†’ Wide shot) or different scenes entirely.
*   **Dual Mode Support:**
    *   **Text-to-Video:** Describe a sequence of events, and the model will execute the cut.
    *   **Image-to-Video:** Start with an input image, and prompt the model to transition into a new scene.
*   **Enhanced Dynamics:** Reduces the "static" or "morphing" feel of standard video generation, creating a more edited, movie-like feel.

## ğŸ“¥ Download

*   **HuggingFace:** [Link to your HF repo]
*   **Civitai:** [Link to your Civitai page]

## ğŸ› ï¸ Usage

### Trigger Words
To activate the shot change effect, it is recommended to use the following trigger words in your prompt:
> **`é•œå¤´åˆ‡æ¢`**

### Recommended LoRA Weight
*   **Strength:** `0.6` to `1.0`
*   If the cut is too abrupt or glitchy, lower the weight. If the scene just morphs without a clear cut, increase the weight.

### Prompting Strategy (How to get the best results)

The key to getting a good shot change is to describe **two distinct states** in your prompt.

**Formula:**
`[Description of Scene A] + [é•œå¤´åˆ‡æ¢] + [Description of Scene B]`

**Examples:**
*   **T2V:** "ç‰¹å†™é•œå¤´å±•ç¤ºä¸€ä½å¥³æ€§çš„çœ¼ç›ï¼Œé•œå¤´åˆ‡æ¢åˆ°ä¸€å¹…å±•ç¤ºå¤œæ™šæœªæ¥èµ›åšæœ‹å…‹åŸå¸‚çš„å¹¿è§’æ— äººæœºé•œå¤´ã€‚"
*   **I2V (with input image of a car):** "æ±½è½¦é©¶ä¸‹é«˜é€Ÿå…¬è·¯ï¼Œé•œå¤´åˆ‡æ¢ï¼Œè½¬åœºåˆ°æµ·æ´‹ä¸Šç©ºçš„æ—¥è½æ™¯è±¡ã€‚"

https://github.com/user-attachments/assets/32c3a79f-d444-4dc9-8fab-aaf6849e2b86


## ğŸš€ Workflows

### ComfyUI
1.  Load your standard Wan2.2 workflow.
2.  Insert a `Load LoRA` node.
3.  Connect **Wan22_shot_lora** to the main model path.
4.  Ensure your positive prompt includes the scene transition description.

### Diffusers (Python)
```python
import torch
from diffusers import WanPipeline # Or appropriate pipeline

pipe = WanPipeline.from_pretrained("Wan-AI/Wan2.1-T2V-1.3B", torch_dtype=torch.float16)
pipe.load_lora_weights("path/to/Wan22_shot_lora.safetensors", adapter_name="shot_change")

prompt = "A man drinking coffee, cut to a busy new york street."
video = pipe(prompt, cross_attention_kwargs={"scale": 0.8}).frames[0]
